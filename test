import torch
class Grid:
    def __init__(self, N, initial_infection_map, device="cpu"):
        """
        Initializes the grid with a given reference infection field.

        Args:
            N (int): Grid size.
            initial_infection_map (torch.Tensor): N x N tensor representing initial infections.
            device (str): Computation device ('cpu' or 'cuda').
        """
        self.N = N
        self.device = device

        # Ensure initial_infection_map is a float tensor and clipped to valid range
        initial_I = initial_infection_map.to(device).float().clamp(0, 1)
        initial_S = 1 - initial_I  # Susceptible is the complement of I
        initial_R = torch.zeros(N, N, device=device)  # No recovered initially

        # Stack S, I, R into a single grid tensor
        self.grid = torch.stack([initial_S, initial_I, initial_R], dim=-1)

    @property
    def S(self):
        """Return the susceptible compartment (S)."""
        return self.grid[..., 0]

    @property
    def I(self):
        """Return the infected compartment (I)."""
        return self.grid[..., 1]

    @property
    def R(self):
        """Return the recovered compartment (R)."""
        return self.grid[..., 2]

    def update(self, delta_S, delta_I, delta_R):
        """
        Update the grid by applying changes (deltas) to all compartments.

        Args:
            delta_S (torch.Tensor): Change in the S compartment.
            delta_I (torch.Tensor): Change in the I compartment.
            delta_R (torch.Tensor): Change in the R compartment.
        """
        self.grid = torch.stack([
            self.S + delta_S,
            self.I + delta_I,
            self.R + delta_R
        ], dim=-1)

    def total_infected(self):
        """Return the total number of infected cells."""
        return torch.sum(self.I)  # Sum of the I compartment

    def __repr__(self):
        return (f"Grid(N={self.N}, requires_grad={self.requires_grad}, "
                f"S_sum={torch.sum(self.S).item()}, "
                f"I_sum={torch.sum(self.I).item()}, "
                f"R_sum={torch.sum(self.R).item()})")

def compute_sparse_weight_matrix(nearest_distances, beta, sigma):
    """
    Compute the sparse weight matrix using the formula:
    weight = β * exp(-r^2 / σ^2)
    """
    return beta * torch.exp(-nearest_distances**2 / sigma**2)

def compute_force_of_infection(nearest_indices, sparse_weights, infected_flat, N, M):
    """
    Compute the force of infection (zeta) for all cells using batched operations.
    """
    infected_neighbors = infected_flat[nearest_indices]  # Shape: (N^2, M)
    zeta_flat = torch.einsum('ij,ij->i', infected_neighbors, sparse_weights)  # Efficient weighted sum
    return zeta_flat.view(N, N)  # Reshape zeta back to grid shape

def runABM(grid, beta, sigma, gamma, n_timesteps, nearest_ind, nearest_dist, tau=0.1):
    """
    Simulate the random walk with infection spread using the Grid class.
    """
    N = grid.N
    for _ in range(n_timesteps - 1):
        # Compute force of infection
        sparse_weights = compute_sparse_weight_matrix(nearest_dist, beta, sigma)
        infected_flat = grid.I.view(-1)  # Flatten grid to (N^2,)
        zeta = compute_force_of_infection(nearest_ind, sparse_weights, infected_flat, N, nearest_ind.shape[1])

        # Compute infection probability (S → I)
        P_inf = 1 - torch.exp(-zeta) + 1e-10  # Ensure numerical stability

        # Gumbel-Softmax for S → I transitions
        logits_S = torch.stack([P_inf, 1 - P_inf], dim=-1).log()
        gumbel_output_S = torch.nn.functional.gumbel_softmax(logits_S, tau=tau, hard=True)
        xi = gumbel_output_S[..., 0]  # Extract transition probabilities for S → I
        d_SI = xi * grid.S

        # Compute recovery probability (I → R)
        P_rec = gamma * torch.ones_like(grid.I)  # Create a tensor matching the shape of grid.I


        # Gumbel-Softmax for I → R transitions
        logits_I = torch.stack([P_rec, 1 - P_rec], dim=-1).log()
        gumbel_output_I = torch.nn.functional.gumbel_softmax(logits_I, tau=tau, hard=True)
        eta = gumbel_output_I[..., 0]  # Extract transition probabilities for I → R
        d_IR = eta * grid.I

        # Update the grid
        grid.update(-d_SI, d_SI - d_IR, d_IR)  # Update S, I, and R compartments

    return gridimport torch
import numpy as np
import h5py
from neighbours import compute_NN
from plotting import *
from compartmentalABM import Grid, runABM
from training import *
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

def run_single_shot():
    from params import N, M, n_timesteps, beta0, sigma0, gamma0, tau

    beta = torch.tensor(beta0, requires_grad=True, device=device)
    sigma = torch.tensor(sigma0, requires_grad=True, device=device)
    gamma = torch.tensor(gamma0, requires_grad=True, device=device)
    # Initialize grid
    #I_0 = get_I_0(N, device, center=(N//2, N//2), sigma=10, infection_rate=0.01)
    I_0 = load_initial_I(N, device, load_from_file='inital_reference_ldn_map.pt')
    grid = Grid(N, I_0, device)
    # Precompute nearest neighbors and sparse weight matrix
    nearest_ind, nearest_dist = compute_NN(N, M, device=device)
    # Simulate model
    grid = runABM(grid, beta, sigma, gamma, n_timesteps, nearest_ind, nearest_dist, tau)

    # Compute loss
    ref_infection_map = load_infection_map('final_reference_ldn_map.pt', device=device)
    loss = loss_function(grid, ref_infection_map)
    loss.backward()

    #plot_grid(grid)
    plot_grid_and_ref(grid, I_0, ref_infection_map)
    print(f"Loss: {loss.item()}")
    print(f"Gradient wrt beta: {beta.grad}")
    print(f"Gradient wrt sigma: {sigma.grad}")
    print(f"Gradient wrt gamma: {gamma.grad}")

    save_infection_map(grid.I, 'infection_map.pt')

def run_parameter_sweep():
    from params import N, M, n_timesteps, tau
    from params import sweep_num, beta0_min_max, sigma0_min_max, gamma0_min_max

    # Generate parameter ranges
    beta_values = torch.linspace(beta0_min_max[0], beta0_min_max[1], sweep_num, device=device)
    sigma_values = torch.linspace(sigma0_min_max[0], sigma0_min_max[1], sweep_num, device=device)
    gamma_values = torch.linspace(gamma0_min_max[0], gamma0_min_max[1], sweep_num, device=device)

    print(beta_values.cpu().numpy())
    print(sigma_values.cpu().numpy())
    print(gamma_values.cpu().numpy())
    return
    # Initialize loss array
    losses = np.zeros((sweep_num, sweep_num, sweep_num))

    # Precompute nearest neighbors and sparse weight matrix
    nearest_ind, nearest_dist = compute_NN(N, M, device=device)

    # Reference infection map
    ref_infection_map = load_infection_map('infection_map.pt', device=device)

    for i, beta in enumerate(beta_values):
        print(i)
        for j, sigma in enumerate(sigma_values):
            for k, gamma in enumerate(gamma_values):
                # Initialize grid
                grid = Grid(N, initial_infection_rate=0.02, device=device)
                # Simulate model
                grid = runABM(grid, beta, sigma, gamma, n_timesteps, nearest_ind, nearest_dist, tau)

                # Compute loss
                loss = loss_function(grid, ref_infection_map)
                losses[i, j, k] = loss.item()

                print(f"beta: {beta:.4f}, sigma: {sigma:.4f}, gamma: {gamma:.4f}, loss: {loss.item()}")

    # Save losses
    #np.save("parameter_sweep_losses.npy", losses)
    #print("Parameter sweep completed. Losses saved to 'parameter_sweep_losses.npy'.")
    # Save losses in HDF5 format
    with h5py.File("parameter_sweep_losses.h5", "w") as hf:
        hf.create_dataset("losses", data=losses)
    print("Parameter sweep completed. Losses saved to 'parameter_sweep_losses.h5'.")

def run_beta_sweep():
    from params import N, M, n_timesteps, tau, sweep_num
    from params import beta0, sigma0, gamma0, beta0_min_max, sigma0_min_max, gamma0_min_max, param_sweep_var

    # Select the parameter to sweep
    if param_sweep_var == 'beta':
        sweep_values = torch.linspace(beta0_min_max[0], beta0_min_max[1], sweep_num, device=device)
        sigma = torch.tensor(sigma0, requires_grad=False, device=device)
        gamma = torch.tensor(gamma0, requires_grad=False, device=device)
    elif param_sweep_var == 'sigma':
        sweep_values = torch.linspace(sigma0_min_max[0], sigma0_min_max[1], sweep_num, device=device)
        beta = torch.tensor(beta0, requires_grad=False, device=device)
        gamma = torch.tensor(gamma0, requires_grad=False, device=device)
    elif param_sweep_var == 'gamma':
        sweep_values = torch.linspace(gamma0_min_max[0], gamma0_min_max[1], sweep_num, device=device)
        beta = torch.tensor(beta0, requires_grad=False, device=device)
        sigma = torch.tensor(sigma0, requires_grad=False, device=device)
    else:
        raise ValueError(f"Invalid parameter to sweep: {param_sweep_var}. Choose 'beta', 'sigma', or 'gamma'.")

    # Initialize loss array and gradient array
    losses = np.zeros(sweep_num)
    gradients = np.zeros(sweep_num)

    # Precompute nearest neighbors and sparse weight matrix
    nearest_ind, nearest_dist = compute_NN(N, M, device=device)

    # Reference infection map
    ref_infection_map = load_infection_map('final_reference_ldn_map.pt', device=device)

    for i, value in enumerate(sweep_values):
        # Explicit handling for the parameter being swept
        if param_sweep_var == 'beta':
            beta = value.clone().detach().requires_grad_(True)
        elif param_sweep_var == 'sigma':
            sigma = value.clone().detach().requires_grad_(True)
        elif param_sweep_var == 'gamma':
            gamma = value.clone().detach().requires_grad_(True)

        # Initialize grid
        I_0 = load_initial_I(N, device, load_from_file='inital_reference_ldn_map.pt')
        grid = Grid(N, I_0, device)
        # Simulate model
        grid = runABM(grid, beta, sigma, gamma, n_timesteps, nearest_ind, nearest_dist, tau)

        # Compute loss
        loss = loss_function(grid, ref_infection_map)
        losses[i] = loss.item()

        # Compute gradients explicitly for the selected parameter
        loss.backward()
        if param_sweep_var == 'beta' and beta.grad is not None:
            gradients[i] = beta.grad.item()
        elif param_sweep_var == 'sigma' and sigma.grad is not None:
            gradients[i] = sigma.grad.item()
        elif param_sweep_var == 'gamma' and gamma.grad is not None:
            gradients[i] = gamma.grad.item()

        # Clear gradients for the next iteration
        if param_sweep_var == 'beta':
            beta.grad = None
        elif param_sweep_var == 'sigma':
            sigma.grad = None
        elif param_sweep_var == 'gamma':
            gamma.grad = None

    # Plot results
    plot_parameter_sweep(sweep_values, losses, gradients, param_sweep_var)

from params import run_mode
print(f"Running mode: {run_mode}")
if run_mode == 'single_shot':
    run_single_shot()
elif run_mode == 'parameter_sweep':
    run_parameter_sweep()
elif run_mode == 'beta_sweep':
    run_beta_sweep()


# Set the run mode
run_mode = 'beta_sweep'

# Parameters for both modes
N = 128
M = 250
n_timesteps = 25
tau = 0.1

# Parameters for 'single_shot' mode
beta0 = 0.01
sigma0 = 4.0
gamma0 = 0.01

# Parameters for 'parameter_sweep' mode
sweep_num = 50
beta0_min_max = [0.0001, 0.1]  # Range for beta
sigma0_min_max = [3., 5.]    # Range for sigma
gamma0_min_max = [0.00, 0.025] # Range for gamma
param_sweep_var = 'beta'         # Parameter to sweep ('beta', 'sigma', or 'gamma')
import os
import torch


def compute_NN(N, M, device='cpu', save_dir='precomputed_data'):
    """
    Efficiently compute the M nearest neighbors for each cell in an NxN grid
    using top-k selection to avoid full sorting. Checks if precomputed data exists
    and loads it if available, otherwise computes and saves the result.

    Args:
        N (int): Grid size.
        M (int): Number of nearest neighbors.
        device (str): Device to perform computations on ('cpu' or 'cuda').
        save_dir (str): Directory to save or load precomputed data.

    Returns:
        torch.Tensor, torch.Tensor: Tensors of nearest neighbor indices and distances.
    """
    # Ensure the save directory exists
    os.makedirs(save_dir, exist_ok=True)

    # Generate the filename based on N and M
    filename = os.path.join(save_dir, f"NN_N{N}_M{M}.pt")

    # Check if the file exists
    if os.path.isfile(filename):
        print(f"Loading precomputed nearest neighbors from {filename}")
        data = torch.load(filename, map_location=device, weights_only=True)
        return data['nearest_indices'], data['nearest_distances']

    print("No precomputed file found. Computing nearest neighbors...")

    # Perform computation
    x = torch.arange(N, device=device).float()
    y = torch.arange(N, device=device).float()
    xx, yy = torch.meshgrid(x, y, indexing='ij')
    coords = torch.stack((xx, yy), dim=-1)  # Shape: (N, N, 2)
    coords_flat = coords.view(-1, 2)  # Flatten grid to (N^2, 2)

    nearest_indices = []
    nearest_distances = []

    # Compute distances for each cell individually
    for i in range(N * N):
        cell_coord = coords_flat[i].unsqueeze(0)  # Shape: (1, 2)
        diff = coords_flat - cell_coord  # Shape: (N^2, 2)
        distances = torch.norm(diff, dim=-1)  # Shape: (N^2,)

        # Find the M nearest neighbors using top-k (excluding self)
        topk_distances, topk_indices = torch.topk(distances, k=M + 1, largest=False)
        nearest_distances.append(topk_distances[1:])  # Exclude self (dist = 0)
        nearest_indices.append(topk_indices[1:])

    # Convert lists to tensors
    nearest_distances = torch.stack(nearest_distances)  # Shape: (N^2, M)
    nearest_indices = torch.stack(nearest_indices)  # Shape: (N^2, M)

    # Save the computed data
    torch.save({'nearest_indices': nearest_indices, 'nearest_distances': nearest_distances}, filename)
    print(f"Saved nearest neighbors to {filename}")

    return nearest_indices, nearest_distances
import matplotlib.pyplot as plt


def plot_grid_and_ref(grid, initial_infection, ref_infection_map, title_suffix=""):
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))

    # Plot Initial Infection Map
    im0 = axes[0, 0].imshow(initial_infection.cpu().detach().numpy(), cmap='plasma')
    axes[0, 0].set_title(f"Initial Infection (I) {title_suffix}")
    plt.colorbar(im0, ax=axes[0, 0])

    # Plot Reference Infection Map
    im1 = axes[0, 1].imshow(ref_infection_map.cpu().detach().numpy(), cmap='plasma')
    axes[0, 1].set_title(f"Reference Infection Map {title_suffix}")
    plt.colorbar(im1, ax=axes[0, 1])

    # Plot Final Infected (I)
    im2 = axes[0, 2].imshow(grid.I.cpu().detach().numpy(), cmap='plasma')
    axes[0, 2].set_title(f"Final Infected (I) {title_suffix}")
    plt.colorbar(im2, ax=axes[0, 2])

    # Plot Susceptible (S)
    im3 = axes[1, 0].imshow(grid.S.cpu().detach().numpy(), cmap='viridis')
    axes[1, 0].set_title(f"Susceptible (S) {title_suffix}")
    plt.colorbar(im3, ax=axes[1, 0])

    # Plot Recovered (R)
    im4 = axes[1, 1].imshow(grid.R.cpu().detach().numpy(), cmap='cividis')
    axes[1, 1].set_title(f"Recovered (R) {title_suffix}")
    plt.colorbar(im4, ax=axes[1, 1])

    # Plot Total Population (N = S + I + R)
    N_grid = grid.S + grid.I + grid.R
    im5 = axes[1, 2].imshow(N_grid.cpu().detach().numpy(), cmap='magma')
    axes[1, 2].set_title(f"Total Population (N = S + I + R) {title_suffix}")
    plt.colorbar(im5, ax=axes[1, 2])

    # Adjust layout
    plt.tight_layout()
    plt.show()

def plot_grid(grid, title_suffix=""):
    fig, axes = plt.subplots(2, 2, figsize=(12, 12))
    # Plot S (Susceptible)
    im1 = axes[0, 0].imshow(grid.S.cpu().detach().numpy(), cmap='viridis')
    axes[0, 0].set_title(f"Susceptible (S) {title_suffix}")
    plt.colorbar(im1, ax=axes[0, 0])
    # Plot I (Infected)
    im2 = axes[0, 1].imshow(grid.I.cpu().detach().numpy(), cmap='plasma')
    axes[0, 1].set_title(f"Infected (I) {title_suffix}")
    plt.colorbar(im2, ax=axes[0, 1])
    # Plot R (Recovered)
    im3 = axes[1, 0].imshow(grid.R.cpu().detach().numpy(), cmap='cividis')
    axes[1, 0].set_title(f"Recovered (R) {title_suffix}")
    plt.colorbar(im3, ax=axes[1, 0])
    # Plot N (S + I + R)
    N_grid = grid.S + grid.I + grid.R
    im4 = axes[1, 1].imshow(N_grid.cpu().detach().numpy(), cmap='magma')
    axes[1, 1].set_title(f"Total Population (N = S + I + R) {title_suffix}")
    plt.colorbar(im4, ax=axes[1, 1])
    # Adjust layout
    plt.tight_layout()
    plt.show()

def plot_parameter_sweep(sweep_values, losses, gradients, param_name, save_path="parameter_sweep.png"):
    """
    Plot the results of the parameter sweep.

    Args:
        sweep_values (torch.Tensor): The range of parameter values.
        losses (np.ndarray): Losses corresponding to the sweep values.
        gradients (np.ndarray): Gradients of the loss w.r.t. the parameter.
        param_name (str): Name of the parameter being swept.
        save_path (str): Path to save the resulting plot image.
    """
    sweep_values_np = sweep_values.cpu().detach().numpy()

    plt.figure(figsize=(10, 5))

    # Loss plot
    plt.subplot(1, 2, 1)
    plt.plot(sweep_values_np, losses, label="Loss")
    plt.xlabel(f"{param_name.capitalize()}")
    plt.ylabel("Loss")
    plt.title(f"Loss vs {param_name.capitalize()}")
    plt.legend()

    # Gradient plot
    plt.subplot(1, 2, 2)
    plt.plot(sweep_values_np, gradients, label=f"d(Loss)/d({param_name.capitalize()})", color="orange")
    plt.xlabel(f"{param_name.capitalize()}")
    plt.ylabel("Gradient")
    plt.title(f"Gradient of Loss w.r.t {param_name.capitalize()}")
    plt.legend()

    plt.tight_layout()
    plt.savefig(save_path)
    plt.show()

import torch
def load_initial_I(N, device, load_from_file=None, center=None, sigma=None, infection_rate=0.02):
    if load_from_file:
        return torch.load(load_from_file, map_location=device, weights_only=True)
        # Generate a Gaussian-based initial infection field
    if center is None or sigma is None:
        raise ValueError("Must provide `center` and `sigma` if not loading from file.")
    # Create coordinate grid
    x, y = torch.meshgrid(torch.arange(N, device=device), torch.arange(N, device=device), indexing='ij')
    # Compute distance from center
    dist_sq = (x - center[0]) ** 2 + (y - center[1]) ** 2
    # Gaussian infection probability
    infection_probs = infection_rate * torch.exp(-dist_sq / (2 * sigma ** 2))
    initial_I = (torch.rand(N, N, device=device) < infection_probs).float()
    return initial_I
def load_infection_map(filename,device='cpu'):
    ref_infection_map = torch.load(filename,map_location=device, weights_only=True)
    return ref_infection_map
def save_infection_map(infection_map, filename):
    torch.save(infection_map.cpu(), filename)
    print(f"Infection map saved to {filename}")
def loss_function(grid, ref_infection_map, loss_type="dice"):
    I_pred = grid.I  # The predicted infection map
    I_ref = ref_infection_map  # The reference infection map
    if loss_type == "sum_of_squares":
        # Sum of squared differences (MSE-like loss)
        return torch.sum((I_pred - I_ref) ** 2)
    elif loss_type == "dice":
        # Dice Loss (1 - Dice Coefficient)
        intersection = torch.sum(I_pred * I_ref)
        union = torch.sum(I_pred) + torch.sum(I_ref)
        dice_coeff = (2.0 * intersection + 1e-6) / (union + 1e-6)  # Add epsilon for numerical stability
        return 1 - dice_coeff  # Dice loss (minimizing means maximizing Dice coefficient)
    elif loss_type == "jaccard":
        # Jaccard Loss (1 - Jaccard Index)
        intersection = torch.sum(I_pred * I_ref)
        union = torch.sum(I_pred + I_ref) - intersection
        jaccard_index = (intersection + 1e-6) / (union + 1e-6)  # Add epsilon for numerical stability
        return 1 - jaccard_index  # Jaccard loss (minimizing means maximizing Jaccard index)
    else:
        raise ValueError(f"Invalid loss_type '{loss_type}'. Choose from 'sum_of_squares', 'dice', or 'jaccard'.")
